---
title: 深度生成模型串讲
keywords: "generative model"
subtitle: 《虽然公式很多，但因为有奶奶都能听懂的动机描述，所以无痛理解的深度生成模型串讲》
---

## 背景

还在学校做深度学习课助教的时候，生成模型一直是一个需要高频答疑的模块，我认为原因包括但不限于：

- 它难：前面的各种分类回归模型，只要懂一句“从输入特征端到端拟合你想要的输出”，一比一地翻译为“输入 -> 输出 -> loss -> backward”就好；但在生成模型部分，课件上通常会先有一些公式推导需要你搞明白，并不好直接翻译成代码流程；
- 它火：我奶奶都会跟我问问 ai 怎么能对话怎么能画画怎么能说话，毋庸置疑地出圈；
- 它有意思：生成模型实现出来的效果，确实能激发人很多脑洞。

所以在当助教的时候，我一直有个计划是重构生成模型部分的课件和作业，让这一部分的讲述更层层递进，门槛更低一些，（也是对得起大家在评教时给我的高分）。
但这事一直推迟跳票，到了自己毕业。

思来想去，我想把相关的思考写成文章分享出来，放到互联网上。
希望能帮到修课的后辈学弟学妹，以及刷到这篇文章并感兴趣的你，也希望能在写文章的输出过程中反刍知识，提升理解。

## 文章目标受众

可能需要的前置知识：

1. 大致修过微积分、线性代数、概率论三门课，至于还记得多少并不关键。
2. 有入门级的 pytorch 使用能力，量化一点就是大于等于 [官网的 60 min 基础教程](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 的掌握度，会写简单网络完成个图像分类任务。

希望读者读完系列文章后能做到“理解主流生成模型原理”，半量化地来说是：

1. 理解主流的生成模型的基本原理。具体来说是能不“背板子”式地写出相应的代码。
2. 能在读相关论文，尤其是背景介绍部分比较少的论文时，也能自己脑补出背景和动机，不会卡死在论文公式和方法上。

当然这也是给自己文章的写作的小要求，希望自己能达到。


## 系列文章目录（动态更新）
